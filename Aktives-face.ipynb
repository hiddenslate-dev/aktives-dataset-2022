{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPHNQrk7y24YmDMXnej7Evw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **FER EMOTION DETECTION and FACIAL LANDMARK DETECTION CODE**\n","\n","The code below detects the facial emotions with FER library"],"metadata":{"id":"zbEtP6aHvpGn"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"I7hK1dB8vGN8"},"outputs":[],"source":["#install libraries\n","!pip install -q fer\n","import tensorflow as tf\n","import cv2\n","from fer import Video\n","from fer import FER\n","import matplotlib.pyplot as plt\n","import os\n","import sys\n","\n","#give the mp4 filename\n","fn='xxxx.mp4'\n","# Face detection with mtcnn\n","detector = FER(mtcnn=True)\n","\n","# process vidoe with FER\n","video = Video(fn)\n","\n","# Output the results and save as csv file \n","raw_data = video.analyze(detector, display=False)\n","df = video.to_pandas(raw_data)\n","df.to_csv('result.csv')\n"]},{"cell_type":"markdown","source":["The code below finds the landmark points"],"metadata":{"id":"gpobHyT1vxOU"}},{"cell_type":"code","source":["# import the necessary packages\n","from matplotlib import pyplot as plt\n","from imutils import face_utils\n","import numpy as np\n","import argparse\n","import imutils\n","import dlib\n","import cv2\n","from tensorflow.keras.preprocessing import image\n","\n","from google.colab.patches import cv2_imshow\n","# initialize dlib's face detector (HOG-based) and then create\n","# the facial landmark predictor\n","args = {\n","\t\"shape_predictor\": \"shape_predictor_68_face_landmarks.dat\",\n","\t\"image\": \"image_name.jpg\"\n","}\n","detector = dlib.get_frontal_face_detector()\n","predictor = dlib.shape_predictor(args[\"shape_predictor\"])\n","\n","# load the input image\n","image= cv2.imread(\"image_name.jpg\")\n","cv2_imshow(image)\n","\n","image = imutils.resize(image, width=500)\n","gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","# detect faces in the grayscale image\n","rects = detector(gray, 1)\n","\n","# loop over the face detections\n","for (i, rect) in enumerate(rects):\n","\tshape = predictor(gray, rect)\n","\tshape = face_utils.shape_to_np(shape)\n","\t# (x, y, w, h) of the bounding box\n","\t(x, y, w, h) = face_utils.rect_to_bb(rect)\n","\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","\n","\tfor (x, y) in shape:\n","\t\tcv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n","\n","# show the output image with the face detections + facial landmarks\n","plt_imshow(\"Output\", image)\n"],"metadata":{"id":"iHaidvAYwH58"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"cjsp9iqQwHng"}}]}